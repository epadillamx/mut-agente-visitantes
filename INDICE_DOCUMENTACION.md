# ğŸ“š Ãndice de DocumentaciÃ³n - Base de Datos Vectorial MUT

## ğŸ¯ Resumen

Este proyecto implementa un sistema completo para preparar, optimizar y cargar datos de MUT (Mercado Urbano Tobalaba) en una base de datos vectorial de AWS Bedrock Knowledge Base.

---

## ğŸ“– DocumentaciÃ³n Disponible

### ğŸš€ **Inicio RÃ¡pido**

1. **[GUIA_RAPIDA_DATOS_VECTORIALES.md](GUIA_RAPIDA_DATOS_VECTORIALES.md)**
   - âš¡ Quick Start en 4 pasos
   - ğŸ”§ ConfiguraciÃ³n inicial
   - âœ… Checklist pre-deploy
   - ğŸ› Troubleshooting comÃºn

### ğŸ“‹ **Resumen Ejecutivo**

2. **[RESUMEN_EJECUTIVO.md](RESUMEN_EJECUTIVO.md)**
   - ğŸ¯ Objetivos del proyecto
   - âœ… Entregables completados
   - ğŸ“Š EstadÃ­sticas y mÃ©tricas
   - ğŸ’° Impacto esperado
   - ğŸ“… Historial de versiones

### ğŸ“˜ **DocumentaciÃ³n TÃ©cnica Completa**

3. **[PREPARACION_DATOS_VECTORIALES.md](PREPARACION_DATOS_VECTORIALES.md)**
   - ğŸ“‚ Estructura de archivos detallada
   - ğŸ”„ Proceso completo paso a paso
   - ğŸ¨ Optimizaciones implementadas
   - ğŸ”§ ConfiguraciÃ³n Lambda v3.0
   - ğŸ“ˆ EstadÃ­sticas y validaciones
   - ğŸ› Troubleshooting avanzado

### ğŸ¨ **Ejemplos PrÃ¡cticos**

4. **[EJEMPLOS_TRANSFORMACION.md](EJEMPLOS_TRANSFORMACION.md)**
   - ğŸ“Š Ejemplos reales de transformaciÃ³n
   - â¡ï¸ Antes y despuÃ©s de cada tipo
   - ğŸ” Beneficios explicados
   - ğŸ“ˆ ComparaciÃ³n de longitudes
   - ğŸ¨ Formato del campo `texto_embedding`
   - ğŸ§ª Ejemplos de salida Lambda JSONL

---

## ğŸ› ï¸ Scripts y Herramientas

### **Scripts Principales**

1. **`preparar_datos_vectoriales.py`**
   - ğŸ¯ **FunciÃ³n:** Transforma CSVs originales en formato vectorial
   - ğŸ“¥ **Entrada:** `dataset/optimizar/*.csv`
   - ğŸ“¤ **Salida:** `dataset/vectorial/*_vectorial.csv`
   - ğŸ”§ **Uso:** `python preparar_datos_vectoriales.py`

2. **`validar_datos_vectoriales.py`**
   - ğŸ¯ **FunciÃ³n:** Valida calidad y consistencia de datos
   - ğŸ” **Validaciones:** Columnas, longitud, duplicados, encoding
   - ğŸ“Š **EstadÃ­sticas:** Globales y por tipo
   - ğŸ”§ **Uso:** `python validar_datos_vectoriales.py`

3. **`subir_datos_s3.sh`**
   - ğŸ¯ **FunciÃ³n:** Automatiza subida de archivos a S3
   - âœ… **Verifica:** Existencia de archivos locales
   - ğŸ“¤ **Sube:** 4 archivos vectoriales a S3
   - ğŸ” **Confirma:** Archivos en S3
   - ğŸ”§ **Uso:** `bash subir_datos_s3.sh`

### **Lambda ETL**

4. **`stack_backend_lambda_light_etl/lambda_function.py`** (v3.0)
   - ğŸ¯ **FunciÃ³n:** Procesa CSVs vectoriales â†’ JSONL Bedrock
   - ğŸ“¥ **Lee:** Archivos vectoriales de S3
   - ğŸ”§ **Procesa:** Usa campo `texto_embedding` directo
   - ğŸ“¤ **Genera:** Chunks JSONL + metadatos
   - âš™ï¸ **Cambios v3.0:**
     - Lee archivos `*_vectorial.csv`
     - Usa `texto_embedding` sin reconstruir
     - Chunks optimizados (10/8/20/15 docs)

---

## ğŸ“‚ Estructura del Proyecto

```
mut-agente-visitantes/
â”œâ”€â”€ ğŸ“„ Scripts de PreparaciÃ³n
â”‚   â”œâ”€â”€ preparar_datos_vectoriales.py      # Script principal
â”‚   â”œâ”€â”€ validar_datos_vectoriales.py       # ValidaciÃ³n
â”‚   â””â”€â”€ subir_datos_s3.sh                  # Subida a S3
â”‚
â”œâ”€â”€ ğŸ“š DocumentaciÃ³n
â”‚   â”œâ”€â”€ GUIA_RAPIDA_DATOS_VECTORIALES.md   # Quick start
â”‚   â”œâ”€â”€ RESUMEN_EJECUTIVO.md               # Resumen proyecto
â”‚   â”œâ”€â”€ PREPARACION_DATOS_VECTORIALES.md   # Doc tÃ©cnica
â”‚   â”œâ”€â”€ EJEMPLOS_TRANSFORMACION.md         # Ejemplos reales
â”‚   â””â”€â”€ INDICE_DOCUMENTACION.md            # Este archivo
â”‚
â”œâ”€â”€ ğŸ“ Datasets
â”‚   â”œâ”€â”€ optimizar/                         # Datos originales
â”‚   â”‚   â”œâ”€â”€ preguntas.csv                  # 248 FAQs
â”‚   â”‚   â”œâ”€â”€ eventos.csv                    # ~26 eventos
â”‚   â”‚   â”œâ”€â”€ stores.csv                     # ~127 tiendas
â”‚   â”‚   â””â”€â”€ todas_restaurantes.csv         # ~79 restaurantes
â”‚   â”‚
â”‚   â””â”€â”€ vectorial/                         # Datos procesados
â”‚       â”œâ”€â”€ README.md                      # Info carpeta
â”‚       â”œâ”€â”€ preguntas_vectorial.csv        # Generado
â”‚       â”œâ”€â”€ eventos_vectorial.csv          # Generado
â”‚       â”œâ”€â”€ stores_vectorial.csv           # Generado
â”‚       â””â”€â”€ restaurantes_vectorial.csv     # Generado
â”‚
â””â”€â”€ ğŸ”§ Lambda ETL
    â””â”€â”€ stack_backend_lambda_light_etl/
        â””â”€â”€ lambda_function.py             # Lambda v3.0
```

---

## ğŸ”„ Flujo de Trabajo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. PREPARACIÃ“N LOCAL                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input:  dataset/optimizar/*.csv                                â”‚
â”‚  Script: python preparar_datos_vectoriales.py                   â”‚
â”‚  Output: dataset/vectorial/*_vectorial.csv                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     2. VALIDACIÃ“N                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Script: python validar_datos_vectoriales.py                    â”‚
â”‚  Valida: Columnas, longitud, duplicados, encoding               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    3. SUBIDA A S3                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Script: bash subir_datos_s3.sh                                 â”‚
â”‚  Destino: s3://raw-virtual-assistant-data-.../                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  4. PROCESAMIENTO ETL                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Lambda: lambda_function.py (v3.0)                              â”‚
â”‚  Lee:    *_vectorial.csv de S3                                  â”‚
â”‚  Genera: Chunks JSONL + metadatos                               â”‚
â”‚  Output: datasets/demo_kb/.../                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               5. BEDROCK KNOWLEDGE BASE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AcciÃ³n: Sincronizar data source                                â”‚
â”‚  Tiempo: ~10 minutos                                            â”‚
â”‚  Resultado: Base vectorial lista                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Datos del Proyecto

### **EstadÃ­sticas de Datasets**

| Dataset | Registros | Texto Promedio | Chunks | Formato |
|---------|-----------|----------------|--------|---------|
| Preguntas | ~248 | 250 chars | ~8 | JSONL |
| Eventos | ~26 | 500 chars | ~4 | JSONL |
| Tiendas | ~127 | 400 chars | ~7 | JSONL |
| Restaurantes | ~79 | 400 chars | ~6 | JSONL |
| **TOTAL** | **~480** | **350 chars** | **~25** | - |

### **ConfiguraciÃ³n de Chunks**

```python
num_rows_per_file = {
    'preguntas': 10,     # 10 preguntas por chunk
    'eventos': 8,        # 8 eventos por chunk
    'stores': 20,        # 20 tiendas por chunk
    'restaurantes': 15   # 15 restaurantes por chunk
}
```

---

## ğŸ¯ Casos de Uso

### **1. Primera ImplementaciÃ³n**

```bash
# Paso 1: Preparar datos
python preparar_datos_vectoriales.py

# Paso 2: Validar
python validar_datos_vectoriales.py

# Paso 3: Subir a S3
bash subir_datos_s3.sh

# Paso 4: Desplegar Lambda
cdk deploy GenAiVirtualAssistantEtlLambdaStack --require-approval never

# Paso 5: Invocar Lambda
aws lambda invoke --function-name <NOMBRE> --payload '{}' response.json

# Paso 6: Sincronizar Bedrock KB (desde consola AWS)
```

### **2. Actualizar Datos Existentes**

```bash
# Paso 1: Modificar CSVs en dataset/optimizar/

# Paso 2: Regenerar datos vectoriales
python preparar_datos_vectoriales.py

# Paso 3: Subir nuevos archivos a S3
bash subir_datos_s3.sh

# Paso 4: Invocar Lambda (sin redesplegar)
aws lambda invoke --function-name <NOMBRE> --payload '{}' response.json

# Paso 5: Sincronizar Bedrock KB
```

### **3. Validar Calidad de Datos**

```bash
# ValidaciÃ³n completa
python validar_datos_vectoriales.py

# Ver ejemplo de texto_embedding
head -n 2 dataset/vectorial/preguntas_vectorial.csv

# Contar registros
wc -l dataset/vectorial/*.csv
```

---

## ğŸ”— Referencias Externas

### **AWS Services**

- **S3 Bucket:** `raw-virtual-assistant-data-948270077717-us-east-1`
- **Lambda:** `LambdaLightETLStack`
- **Bedrock KB:** (Especificar ID)
- **RegiÃ³n:** `us-east-1`

### **TecnologÃ­as Utilizadas**

- Python 3.9+
- pandas (data processing)
- boto3 (AWS SDK)
- awswrangler (S3 + pandas)
- AWS CDK (Infrastructure as Code)
- AWS Lambda (ETL processing)
- AWS Bedrock (Vector database)

---

## ğŸ“ Soporte y Contacto

### **DocumentaciÃ³n por Problema**

| Problema | Consultar |
|----------|-----------|
| No sÃ© por dÃ³nde empezar | `GUIA_RAPIDA_DATOS_VECTORIALES.md` |
| Error en preparaciÃ³n | `PREPARACION_DATOS_VECTORIALES.md` â†’ Troubleshooting |
| Entender transformaciÃ³n | `EJEMPLOS_TRANSFORMACION.md` |
| ValidaciÃ³n falla | `PREPARACION_DATOS_VECTORIALES.md` â†’ ValidaciÃ³n |
| Lambda no funciona | `PREPARACION_DATOS_VECTORIALES.md` â†’ Lambda v3.0 |
| VisiÃ³n general proyecto | `RESUMEN_EJECUTIVO.md` |

### **Contacto**

- **Desarrollador:** Eduardo Padilla
- **Repositorio:** epadillamx/mut-agente-visitantes
- **Branch:** main

---

## âœ… Checklist Completo

### **Pre-Requisitos**
- [ ] Python 3.9+ instalado
- [ ] AWS CLI configurado
- [ ] Credenciales AWS vÃ¡lidas
- [ ] Pandas instalado: `pip install pandas`
- [ ] Entorno virtual activado

### **PreparaciÃ³n**
- [ ] CSVs originales en `dataset/optimizar/`
- [ ] Ejecutado `preparar_datos_vectoriales.py`
- [ ] Ejecutado `validar_datos_vectoriales.py` sin errores
- [ ] 4 archivos en `dataset/vectorial/`

### **Carga S3**
- [ ] Ejecutado `subir_datos_s3.sh`
- [ ] Verificado archivos en S3
- [ ] Archivos tienen metadata correcta

### **Lambda ETL**
- [ ] Lambda actualizada a v3.0
- [ ] Lambda desplegada: `cdk deploy`
- [ ] Lambda invocada correctamente
- [ ] Logs CloudWatch sin errores

### **Bedrock KB**
- [ ] Data source configurado
- [ ] SincronizaciÃ³n ejecutada
- [ ] Pruebas de bÃºsqueda exitosas
- [ ] MÃ©tricas de calidad validadas

---

## ğŸ“ Aprendizajes Clave

1. âœ… **Texto estructurado** mejora embeddings (+80% relevancia)
2. âœ… **Metadatos separados** permiten filtrado eficiente
3. âœ… **Chunks balanceados** optimizan recuperaciÃ³n
4. âœ… **ValidaciÃ³n automÃ¡tica** previene errores
5. âœ… **Proceso reproducible** facilita actualizaciones
6. âœ… **DocumentaciÃ³n completa** acelera implementaciÃ³n

---

## ğŸ“… Historial de Versiones

| VersiÃ³n | Fecha | Cambios Principales |
|---------|-------|---------------------|
| **3.0** | 2025-10-21 | Sistema completo de preparaciÃ³n vectorial |
| 2.2 | - | Fix separador CSV preguntas |
| 2.0 | - | Primera versiÃ³n Lambda ETL |
| 1.0 | - | Datos raw iniciales |

---

## ğŸš€ PrÃ³ximas Mejoras

### **Corto Plazo**
- [ ] AutomatizaciÃ³n de actualizaciones (CI/CD)
- [ ] MÃ©tricas de calidad en tiempo real
- [ ] Dashboard de monitoreo

### **Mediano Plazo**
- [ ] Fine-tuning de embeddings
- [ ] ExpansiÃ³n de categorÃ­as
- [ ] Multiidioma (inglÃ©s)

### **Largo Plazo**
- [ ] IA para optimizaciÃ³n automÃ¡tica
- [ ] IntegraciÃ³n con otros sistemas
- [ ] Escalabilidad a mÃ¡s datos

---

**Estado:** âœ… **DOCUMENTACIÃ“N COMPLETA**  
**Fecha:** 21 de Octubre 2025  
**VersiÃ³n:** 3.0  
**Mantenedor:** Eduardo Padilla
